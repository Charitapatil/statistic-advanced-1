{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha1KgYMNrVDE"
      },
      "outputs": [],
      "source": [
        "1. Explain the properties of the F-distribution.\n",
        "The F-distribution is a continuous probability distribution that is commonly used in statistical hypothesis testing, particularly in the analysis of variance (ANOVA) and regression analysis. Here are the key properties of the F-distribution:\n",
        "\n",
        "Non-Symmetry: The F-distribution is not symmetric; it is skewed to the right.\n",
        "\n",
        "Degrees of Freedom: The F-distribution is defined by two parameters, known as degrees of freedom. These are typically denoted as\n",
        "v\n",
        "1\n",
        "v\n",
        "1\n",
        "​\n",
        "  (numerator degrees of freedom) and\n",
        "v\n",
        "2\n",
        "v\n",
        "2\n",
        "​\n",
        "  (denominator degrees of freedom).\n",
        "\n",
        "Non-Negative: The F-distribution is always non-negative.\n",
        "\n",
        "Three-Reverse Formula: There is a property known as the \"three-reverse formula\" which states that\n",
        "F\n",
        "α\n",
        "(\n",
        "n\n",
        "1\n",
        ",\n",
        "n\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "F\n",
        "1\n",
        "−\n",
        "α\n",
        "(\n",
        "n\n",
        "2\n",
        ",\n",
        "n\n",
        "1\n",
        ")\n",
        "F\n",
        "α\n",
        "​\n",
        " (n\n",
        "1\n",
        "​\n",
        " ,n\n",
        "2\n",
        "​\n",
        " )=\n",
        "F\n",
        "1−α\n",
        "​\n",
        " (n\n",
        "2\n",
        "​\n",
        " ,n\n",
        "1\n",
        "​\n",
        " )\n",
        "1\n",
        "​\n",
        " .\n",
        "\n",
        "Python Code to Work with the F-Distribution\n",
        "To work with the F-distribution in Python, you can use the scipy.stats module, which provides various functions to handle the F-distribution. Here is an example of how to use these functions:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Define the degrees of freedom\n",
        "v1 = 5  # Numerator degrees of freedom\n",
        "v2 = 10 # Denominator degrees of freedom\n",
        "\n",
        "# Generate random samples from the F-distribution\n",
        "samples = f.rvs(v1, v2, size=1000)\n",
        "\n",
        "# Plot the histogram of the samples\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n",
        "\n",
        "# Plot the PDF of the F-distribution\n",
        "x = np.linspace(f.ppf(0.01, v1, v2), f.ppf(0.99, v1, v2), 100)\n",
        "plt.plot(x, f.pdf(x, v1, v2), 'r-', lw=2, label='F-distribution PDF')\n",
        "\n",
        "plt.title('F-Distribution with v1=5 and v2=10')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate the CDF at a specific point\n",
        "point = 2.0\n",
        "cdf_value = f.cdf(point, v1, v2)\n",
        "print(f'CDF at x={point}: {cdf_value}')\n",
        "\n",
        "# Calculate the PPF (percent point function) at a specific probability\n",
        "probability = 0.95\n",
        "ppf_value = f.ppf(probability, v1, v2)\n",
        "print(f'PPF at p={probability}: {ppf_value}')\n",
        "\n",
        "2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "The F-distribution is used in several types of statistical tests, particularly in the context of comparing variances and means across different groups. Here are the key applications and why the F-distribution is appropriate for these tests:\n",
        "\n",
        "Types of Statistical Tests Using the F-Distribution\n",
        "ANOVA (Analysis of Variance):\n",
        "\n",
        "Purpose: ANOVA is used to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups.\n",
        "Why F-Distribution: The F-distribution is used to compare the variance between the groups to the variance within the groups. A high F-value indicates that the variance between the groups is significantly greater than the variance within the groups, suggesting that the group means are not equal.\n",
        "F-Test for Equality of Variances:\n",
        "\n",
        "Purpose: This test is used to determine if the variances of two populations are equal.\n",
        "Why F-Distribution: The F-distribution is used to compare the ratio of the variances of two samples. If the variances are equal, the F-ratio should be close to 1. A significantly different F-ratio suggests that the variances are not equal.\n",
        "Regression Analysis:\n",
        "\n",
        "Purpose: In regression analysis, the F-distribution is used to test the overall significance of the model.\n",
        "Why F-Distribution: The F-test in regression compares the variance explained by the model to the residual variance. A high F-value indicates that the model explains a significant portion of the variance in the dependent variable.\n",
        "Python Code Example\n",
        "Here is a Python code example demonstrating the use of the F-distribution in an ANOVA test:\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=5, scale=2, size=100)\n",
        "group2 = np.random.normal(loc=7, scale=2, size=100)\n",
        "group3 = np.random.normal(loc=9, scale=2, size=100)\n",
        "\n",
        "# Perform ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f'F-statistic: {f_statistic}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group1, bins=20, alpha=0.5, label='Group 1')\n",
        "plt.hist(group2, bins=20, alpha=0.5, label='Group 2')\n",
        "plt.hist(group3, bins=20, alpha=0.5, label='Group 3')\n",
        "plt.legend()\n",
        "plt.title('Histogram of Group Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?\n",
        "Key Assumptions for Conducting an F-Test to Compare the Variances of Two Populations\n",
        "Normality: The data in both populations should be normally distributed. This is a critical assumption because the F-test is sensitive to deviations from normality.\n",
        "\n",
        "Independence: The samples from the two populations should be independent of each other. This means that the observations in one sample do not influence the observations in the other sample.\n",
        "\n",
        "Homogeneity of Variances: The variances of the two populations should be equal under the null hypothesis. This is what the F-test aims to test.\n",
        "\n",
        "Python Code Example\n",
        "Here is a Python code example demonstrating how to perform an F-test to compare the variances of two populations:\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate sample data for two populations\n",
        "np.random.seed(0)\n",
        "population1 = np.random.normal(loc=5, scale=2, size=100)\n",
        "population2 = np.random.normal(loc=7, scale=2, size=100)\n",
        "\n",
        "# Perform the F-test\n",
        "f_statistic, p_value = stats.f_oneway(population1, population2)\n",
        "\n",
        "# Print the results\n",
        "print(f'F-statistic: {f_statistic}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject the null hypothesis: The variances are not equal.')\n",
        "else:\n",
        "    print('Fail to reject the null hypothesis: The variances are equal.')\n",
        "\n",
        "    4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "    Purpose of ANOVA\n",
        "The purpose of ANOVA (Analysis of Variance) is to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups. ANOVA is an omnibus test, meaning it tests for a difference overall between all groups. It compares the variance between the groups to the variance within the groups to determine if the differences in means are significant3512.\n",
        "\n",
        "Differences Between ANOVA and T-Test\n",
        "Number of Groups:\n",
        "\n",
        "ANOVA: Used to compare the means of three or more groups.\n",
        "T-Test: Used to compare the means of two groups249.\n",
        "Type of Test:\n",
        "\n",
        "ANOVA: An omnibus test that provides a single p-value indicating whether there is a significant difference among the group means.\n",
        "T-Test: Provides a direct comparison between two groups, resulting in a single p-value for that comparison35.\n",
        "Assumptions:\n",
        "\n",
        "ANOVA: Assumes normality, independence, and homogeneity of variances across groups.\n",
        "T-Test: Also assumes normality and independence, but only needs to consider the variances of two groups46.\n",
        "Python Code Example\n",
        "Here is a Python code example demonstrating how to perform an ANOVA and a t-test:\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=5, scale=2, size=100)\n",
        "group2 = np.random.normal(loc=7, scale=2, size=100)\n",
        "group3 = np.random.normal(loc=9, scale=2, size=100)\n",
        "\n",
        "# Perform ANOVA\n",
        "f_statistic, p_value_anova = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Perform t-test between group1 and group2\n",
        "t_statistic, p_value_ttest = stats.ttest_ind(group1, group2)\n",
        "\n",
        "# Print the results\n",
        "print(f'ANOVA F-statistic: {f_statistic}')\n",
        "print(f'ANOVA P-value: {p_value_anova}')\n",
        "print(f'T-test t-statistic: {t_statistic}')\n",
        "print(f'T-test P-value: {p_value_ttest}')\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group1, bins=20, alpha=0.5, label='Group 1')\n",
        "plt.hist(group2, bins=20, alpha=0.5, label='Group 2')\n",
        "plt.hist(group3, bins=20, alpha=0.5, label='Group 3')\n",
        "plt.legend()\n",
        "plt.title('Histogram of Group Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
        "than two groups.\n",
        "When and Why to Use One-Way ANOVA Instead of Multiple T-Tests\n",
        "When to Use One-Way ANOVA\n",
        "One-way ANOVA is used when you need to compare the means of more than two independent groups. It is particularly useful in experimental designs where you have multiple treatment groups and a control group, or when you want to compare the means of different categories of a single independent variable.\n",
        "\n",
        "Why Use One-Way ANOVA Instead of Multiple T-Tests\n",
        "Control of Type I Error: Conducting multiple t-tests increases the likelihood of committing a Type I error (incorrectly rejecting the null hypothesis). One-way ANOVA controls the overall Type I error rate across all group comparisons, making it a more reliable method for multiple group comparisons345.\n",
        "\n",
        "Efficiency: One-way ANOVA provides a single p-value that indicates whether there is a significant difference among the group means. This is more efficient than performing multiple t-tests, which would require multiple comparisons and adjustments for multiple testing26.\n",
        "\n",
        "Statistical Power: ANOVA is generally more powerful than multiple t-tests when comparing more than two groups. It can detect smaller differences between group means with greater accuracy37.\n",
        "\n",
        "Python Code Example\n",
        "Here is a Python code example demonstrating how to perform a one-way ANOVA:\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=5, scale=2, size=100)\n",
        "group2 = np.random.normal(loc=7, scale=2, size=100)\n",
        "group3 = np.random.normal(loc=9, scale=2, size=100)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f'F-statistic: {f_statistic}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject the null hypothesis: There is a significant difference between the group means.')\n",
        "else:\n",
        "    print('Fail to reject the null hypothesis: There is no significant difference between the group means.')\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group1, bins=20, alpha=0.5, label='Group 1')\n",
        "plt.hist(group2, bins=20, alpha=0.5, label='Group 2')\n",
        "plt.hist(group3, bins=20, alpha=0.5, label='Group 3')\n",
        "plt.legend()\n",
        "plt.title('Histogram of Group Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=5, scale=2, size=100)\n",
        "group2 = np.random.normal(loc=7, scale=2, size=100)\n",
        "group3 = np.random.normal(loc=9, scale=2, size=100)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f'F-statistic: {f_statistic}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject the null hypothesis: There is a significant difference between the group means.')\n",
        "else:\n",
        "    print('Fail to reject the null hypothesis: There is no significant difference between the group means.')\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group1, bins=20, alpha=0.5, label='Group 1')\n",
        "plt.hist(group2, bins=20, alpha=0.5, label='Group 2')\n",
        "plt.hist(group3, bins=20, alpha=0.5, label='Group 3')\n",
        "plt.legend()\n",
        "plt.title('Histogram of Group Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?\n",
        "Variance Partitioning in ANOVA\n",
        "In ANOVA, the total variance of the data is partitioned into two components:\n",
        "\n",
        "Between-Group Variance (SSB):\n",
        "\n",
        "Measures the variability between the group means and the overall mean (grand mean).\n",
        "Indicates how much the group means differ from one another.\n",
        "Within-Group Variance (SSW):\n",
        "\n",
        "Measures the variability within each group around their respective group means.\n",
        "Reflects the natural variability in the data within groups.\n",
        "F-statistic Calculation\n",
        "The F-statistic is the ratio of the between-group variance to the within-group variance:\n",
        "\n",
        "𝐹\n",
        "=\n",
        "MSB\n",
        "MSW\n",
        "F=\n",
        "MSW\n",
        "MSB\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "Mean Square Between (MSB) =\n",
        "SSB\n",
        "df\n",
        "between\n",
        "df\n",
        "between\n",
        "​\n",
        "\n",
        "SSB\n",
        "​\n",
        " , where\n",
        "df\n",
        "between\n",
        "=\n",
        "Number of Groups\n",
        "−\n",
        "1\n",
        "df\n",
        "between\n",
        "​\n",
        " =Number of Groups−1.\n",
        "Mean Square Within (MSW) =\n",
        "SSW\n",
        "df\n",
        "within\n",
        "df\n",
        "within\n",
        "​\n",
        "\n",
        "SSW\n",
        "​\n",
        " , where\n",
        "df\n",
        "within\n",
        "=\n",
        "Total Observations\n",
        "−\n",
        "Number of Groups\n",
        "df\n",
        "within\n",
        "​\n",
        " =Total Observations−Number of Groups.\n",
        "Steps in Variance Partitioning\n",
        "Calculate the grand mean of all observations.\n",
        "Compute SSB (sum of squares between groups) by summing the squared differences between each group mean and the grand mean, weighted by group size.\n",
        "Compute SSW (sum of squares within groups) by summing the squared differences within each group.\n",
        "import numpy as np\n",
        "\n",
        "# Example data: Scores from three groups\n",
        "group1 = np.array([85, 90, 88, 86, 89])\n",
        "group2 = np.array([78, 76, 80, 79, 77])\n",
        "group3 = np.array([92, 95, 93, 91, 94])\n",
        "\n",
        "# Combine groups and calculate grand mean\n",
        "groups = [group1, group2, group3]\n",
        "all_data = np.concatenate(groups)\n",
        "grand_mean = np.mean(all_data)\n",
        "\n",
        "# Between-Group Variance (SSB)\n",
        "n_groups = len(groups)\n",
        "ssb = sum(len(group) * (np.mean(group) - grand_mean)**2 for group in groups)\n",
        "\n",
        "# Within-Group Variance (SSW)\n",
        "ssw = sum(np.sum((group - np.mean(group))**2) for group in groups)\n",
        "\n",
        "# Degrees of freedom\n",
        "df_between = n_groups - 1\n",
        "df_within = len(all_data) - n_groups\n",
        "\n",
        "# Mean Squares\n",
        "msb = ssb / df_between\n",
        "msw = ssw / df_within\n",
        "\n",
        "# F-statistic\n",
        "f_statistic = msb / msw\n",
        "\n",
        "# Print Results\n",
        "print(f\"SSB (Between-Group): {ssb}\")\n",
        "print(f\"SSW (Within-Group): {ssw}\")\n",
        "print(f\"MSB (Mean Square Between): {msb}\")\n",
        "print(f\"MSW (Mean Square Within): {msw}\")\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "\n",
        "7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
        "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "Comparison of Classical (Frequentist) and Bayesian ANOVA\n",
        "1. Handling Uncertainty\n",
        "Classical (Frequentist) Approach:\n",
        "\n",
        "Assumes data are fixed, and uncertainty arises from sampling variability.\n",
        "Provides p-values to determine whether the null hypothesis (no differences between groups) can be rejected.\n",
        "Does not assign probabilities to hypotheses; the null is either rejected or not rejected.\n",
        "Bayesian Approach:\n",
        "\n",
        "Treats parameters as random variables with probability distributions.\n",
        "Uses prior beliefs (prior distributions) and updates them with data (likelihood) to compute posterior distributions.\n",
        "Allows direct probability statements about hypotheses (e.g., \"The probability of group differences is 95%.\").\n",
        "2. Parameter Estimation\n",
        "Classical Approach:\n",
        "Estimates parameters (e.g., means, variances) using point estimates like the sample mean and variance.\n",
        "Provides confidence intervals to express the uncertainty around these estimates.\n",
        "Bayesian Approach:\n",
        "Estimates parameters as distributions (posterior distributions).\n",
        "Produces credible intervals, which directly represent the range of values with a specified probability (e.g., 95%).\n",
        "3. Hypothesis Testing\n",
        "Classical Approach:\n",
        "\n",
        "Uses F-statistics and p-values to determine if group differences are statistically significant.\n",
        "Hypothesis testing is dichotomous: reject or fail to reject the null hypothesis.\n",
        "Bayesian Approach:\n",
        "\n",
        "Directly calculates the posterior probability of the null or alternative hypothesis.\n",
        "Can compare models using Bayesian model comparison techniques, such as Bayes factors.\n",
        "Allows for nuanced interpretation without requiring binary decision-making.\n",
        "Python Code: Classical vs. Bayesian ANOVA\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Example data\n",
        "group1 = [85, 90, 88, 86, 89]\n",
        "group2 = [78, 76, 80, 79, 77]\n",
        "group3 = [92, 95, 93, 91, 94]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(\"Classical ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: significant differences exist.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: no significant differences.\")\n",
        "Bayesian ANOVA (Using PyMC for Bayesian Modeling)\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "data = {\n",
        "    \"group1\": [85, 90, 88, 86, 89],\n",
        "    \"group2\": [78, 76, 80, 79, 77],\n",
        "    \"group3\": [92, 95, 93, 91, 94]\n",
        "}\n",
        "\n",
        "# Convert data to a single array with group labels\n",
        "all_data = np.concatenate([data[\"group1\"], data[\"group2\"], data[\"group3\"]])\n",
        "group_labels = np.concatenate([[1]*len(data[\"group1\"]), [2]*len(data[\"group2\"]), [3]*len(data[\"group3\"])])\n",
        "\n",
        "# Bayesian ANOVA Model\n",
        "with pm.Model() as model:\n",
        "    # Priors for group means and shared variance\n",
        "    mu_group = pm.Normal(\"mu_group\", mu=0, sigma=10, shape=3)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
        "\n",
        "    # Likelihood\n",
        "    obs = pm.Normal(\"obs\", mu=mu_group[group_labels - 1], sigma=sigma, observed=all_data)\n",
        "\n",
        "    # Posterior sampling\n",
        "    trace = pm.sample(1000, return_inferencedata=True)\n",
        "\n",
        "# Summary of results\n",
        "print(\"Bayesian ANOVA Results:\")\n",
        "print(az.summary(trace, var_names=[\"mu_group\", \"sigma\"]))\n",
        "\n",
        "# Posterior plots\n",
        "az.plot_posterior(trace, var_names=[\"mu_group\"])\n",
        "\n",
        "\n",
        "8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "V Profession A: [48, 52, 55, 60, 62'\n",
        "V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
        "F-Test to Compare Variances\n",
        "The F-test is used to compare the variances of two samples to determine if they are equal. It involves calculating the F-statistic as:\n",
        "\n",
        "𝐹\n",
        "=\n",
        "Variance of Group A\n",
        "Variance of Group B\n",
        "F=\n",
        "Variance of Group B\n",
        "Variance of Group A\n",
        "​\n",
        "\n",
        "The larger variance is placed in the numerator to ensure\n",
        "𝐹\n",
        "≥\n",
        "1\n",
        "F≥1.\n",
        "The p-value is calculated based on the F-distribution with degrees of freedom for the two groups.\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "# Data for the two professions\n",
        "profession_a = [48, 52, 55, 60, 62]\n",
        "profession_b = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Variances of the two groups\n",
        "var_a = np.var(profession_a, ddof=1)  # Sample variance (use ddof=1 for unbiased estimate)\n",
        "var_b = np.var(profession_b, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic\n",
        "if var_a > var_b:\n",
        "    f_stat = var_a / var_b\n",
        "    dfn, dfd = len(profession_a) - 1, len(profession_b) - 1\n",
        "else:\n",
        "    f_stat = var_b / var_a\n",
        "    dfn, dfd = len(profession_b) - 1, len(profession_a) - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - f.cdf(f_stat, dfn, dfd))  # Two-tailed test\n",
        "\n",
        "# Results\n",
        "print(\"F-Test Results:\")\n",
        "print(f\"Variance of Profession A: {var_a:.2f}\")\n",
        "print(f\"Variance of Profession B: {var_b:.2f}\")\n",
        "print(f\"F-statistic: {f_stat:.2f}\")\n",
        "print(f\"Degrees of Freedom (dfn, dfd): ({dfn}, {dfd})\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variances.\")\n",
        "\n",
        "9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "average heights between three different regions with the following data1\n",
        "V Region A: [160, 162, 165, 158, 164]\n",
        "V Region B: [172, 175, 170, 168, 174]\n",
        "V Region C: [180, 182, 179, 185, 183]\n",
        "V Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
        "V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
        "One-Way ANOVA to Test Differences in Average Heights\n",
        "One-way ANOVA compares the means of three or more groups to determine if there are statistically significant differences among them. Here’s how to perform the test and interpret the results.\n",
        " from scipy.stats import f_oneway\n",
        "\n",
        "# Data for the three regions\n",
        "region_a = [160, 162, 165, 158, 164]\n",
        "region_b = [172, 175, 170, 168, 174]\n",
        "region_c = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(region_a, region_b, region_c)\n",
        "\n",
        "# Results\n",
        "print(\"One-Way ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat:.2f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There are statistically significant differences in average heights between the regions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No statistically significant differences in average heights between the regions.\")\n",
        "Steps in the Code\n",
        "Data Input:\n",
        "Heights for each region are provided as lists.\n",
        "One-Way ANOVA Test:\n",
        "Use scipy.stats.f_oneway() to compute the F-statistic and p-value.\n",
        "Results Interpretation:\n",
        "The F-statistic quantifies the ratio of between-group variance to within-group variance.\n",
        "The p-value determines if the observed differences are statistically significant (compared to the significance level,\n",
        "𝛼\n",
        "=\n",
        "0.05\n",
        "α=0.05).\n",
        ""
      ]
    }
  ]
}